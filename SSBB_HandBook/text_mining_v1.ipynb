{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bec7896c-bacf-4986-aa35-2aee1b616b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "import spacy\n",
    "from wordcloud import WordCloud\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad4e9bce-5939-4e08-9ad9-924bd21c0fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tidy_text(_txt):\n",
    "    _doc = DBAS_NLP(_txt)\n",
    "    _tidy_word = [token.text for token in _doc if not token.is_stop]\n",
    "    return \" \".join(_tidy_word)\n",
    "\n",
    "def get_lemma_pos(_txt):\n",
    "    _doc = DBAS_NLP(_txt)\n",
    "    _d = {\"_POS\": [], \"_LEMMA\": []}\n",
    "    for _token in _doc:\n",
    "        _d[\"_POS\"].append(_token.pos_)\n",
    "        _d[\"_LEMMA\"].append(_token.lemma_)\n",
    "    return _d\n",
    "\n",
    "def _generate_word_cloud(_txt):\n",
    "    x, y = np.ogrid[:300, :300]\n",
    "    mask = (x - 150) ** 2 + (y - 150) ** 2 > 130**2\n",
    "    mask = 255 * mask.astype(int)\n",
    "    wc = WordCloud(background_color=\"white\", repeat=True, mask=mask)\n",
    "    wc.generate(_txt)\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(wc, interpolation=\"bilinear\")\n",
    "    plt.show()\n",
    "\n",
    "def get_word_rep(_word, _rep):\n",
    "    repeated_word = f\"{_word} \" * _rep\n",
    "    return repeated_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a614209-4731-4b1d-96ad-1e85ef0ff47c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_challenges = pl.read_csv(\n",
    "    r\"/Users/malleshamyamulla/Desktop/SSBBA/MBB_PROJECT/data/dbas_sds_challenges.csv\"\n",
    ").with_row_count()\n",
    "\n",
    "los_samples = []\n",
    "for _ in range(10):\n",
    "    _df = df_challenges.sample(10, with_replacement=False,seed=100)\n",
    "    los_samples.append(_df)\n",
    "\n",
    "df_conso = pl.concat(los_samples).to_pandas()\n",
    "\n",
    "DBAS_NLP = spacy.load(\n",
    "    \"en_core_web_sm\"\n",
    ")\n",
    "\n",
    "df_conso[\"_tidy_text_1\"] = df_conso[\"#CHALLENGE\"].apply(lambda x: get_tidy_text(x))\n",
    "\n",
    "los_doc_dicts = []\n",
    "for _sen in df_conso[\"_tidy_text_1\"]:\n",
    "    _d = get_lemma_pos(_sen)\n",
    "    los_doc_dicts.append(_d)\n",
    "\n",
    "los_dfs = []\n",
    "for _d in los_doc_dicts:\n",
    "    _DF = pd.DataFrame(_d)\n",
    "    los_dfs.append(_DF)\n",
    "\n",
    "DF_POS = pd.concat(los_dfs)\n",
    "\n",
    "DF_POS_TIDY = DF_POS[DF_POS[\"_POS\"] != \"PUNCT\"]\n",
    "\n",
    "_LOS_NOUNS = (\n",
    "    DF_POS_TIDY[DF_POS_TIDY[\"_POS\"] == \"NOUN\"]\n",
    "    .groupby(\"_LEMMA\")\n",
    "    .count()\n",
    "    .reset_index()\n",
    "    .sort_values(\"_POS\", ascending=False)\n",
    ")\n",
    "\n",
    "_ADJCT = (\n",
    "    DF_POS_TIDY[DF_POS_TIDY[\"_POS\"] == \"ADJ\"]\n",
    "    .groupby(\"_LEMMA\")\n",
    "    .count()\n",
    "    .reset_index()\n",
    "    .sort_values(\"_POS\", ascending=False)\n",
    ")\n",
    "\n",
    "_VERBS = (\n",
    "    DF_POS_TIDY[DF_POS_TIDY[\"_POS\"] == \"VERB\"]\n",
    "    .groupby(\"_LEMMA\")\n",
    "    .count()\n",
    "    .reset_index()\n",
    "    .sort_values(\"_POS\", ascending=False)\n",
    ")\n",
    "\n",
    "LOS_VERBS = _VERBS[[\"_LEMMA\", \"_POS\"]].apply(lambda x: get_word_rep(x[0], x[1]), axis=1)\n",
    "LOS_NOUNS = _LOS_NOUNS[[\"_LEMMA\", \"_POS\"]].apply(lambda x: get_word_rep(x[0], x[1]), axis=1)\n",
    "LOS_ADJ = _ADJCT[[\"_LEMMA\", \"_POS\"]].apply(lambda x: get_word_rep(x[0], x[1]), axis=1)\n",
    "\n",
    "todos_verb_list = []\n",
    "for _verb in LOS_VERBS:\n",
    "    _vs = _verb.split(\" \")\n",
    "    todos_verb_list.extend(_vs)\n",
    "\n",
    "todos_noun_list = []\n",
    "for _verb in LOS_NOUNS:\n",
    "    _vs = _verb.split(\" \")\n",
    "    todos_noun_list.extend(_vs)\n",
    "\n",
    "todos_adj_list = []\n",
    "for _verb in LOS_ADJ:\n",
    "    _vs = _verb.split(\" \")\n",
    "    todos_adj_list.extend(_vs)\n",
    "\n",
    "text_verb = \" \".join([_word for _word in todos_verb_list if len(_word) != 0])\n",
    "text_noun = \" \".join([_word for _word in todos_noun_list if len(_word) != 0])\n",
    "text_adj = \" \".join([_word for _word in todos_adj_list if len(_word) != 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "03ee9cd2-4db8-4122-820d-4dfe331d6900",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'extract extract extract extract extract extract extract extract extract extract extract extract extract extract extract extract extract extract extract extract take take take take take take take take take take take take take take take take take take take take consume consume consume consume consume consume consume consume consume consume handle handle handle handle handle handle handle handle handle handle'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_verb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d08634-775d-4074-a0ab-f016359b2aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_PII=pd.read_excel(r'/Users/malleshamyamulla/Desktop/SSBBA/MBB_PROJECT/data/class_pii_phi_tiny_v2.xlsx',sheet_name='PIIPHI')\n",
    "df_NOPII=pd.read_excel(r'/Users/malleshamyamulla/Desktop/SSBBA/MBB_PROJECT/data/class_pii_phi_tiny_v2.xlsx',sheet_name='NOPIIPHI')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf488378-2662-486d-a177-9960dbdbc27b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_NOPII.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9548bfe-a328-43cd-92a1-810c4d018331",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_PII.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7510a7f4-f184-45a2-b429-e6b4d8f854c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
